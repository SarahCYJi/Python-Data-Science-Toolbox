Step One
When you got the dataset
# Print the head of the homelessness data
print(homelessness.head())
# Print information about homelessness
print(homelessness.info())
# Print the shape of homelessness
print(homelessness.shape)
# Print a description of homelessness
print(homelessness.describe())
# Import pandas using the alias pd
import pandas as pd
# Print the values of homelessness
print(homelessness.values)
# Print the column index of homelessness
print(homelessness.columns)
# Print the row index of homelessness
print(homelessness.index)




Step Two
Sort and filter 

Sort on â€¦	Syntax
one column	df.sort_values("breed")
multiple columns	df.sort_values(["breed", "weight_kg"])
# Sort homelessness by descending family members
homelessness_fam = homelessness.sort_values("family_members",ascending=False)
# Print the top few rows
print(homelessness_fam.head())

# Sort homelessness by region, then descending family members
homelessness_reg_fam = homelessness.sort_values(["region","family_members"],ascending=[True,False])
# Print the top few rows
print(homelessness_reg_fam.head())

Step 3 select 
To select only "col_a" of the DataFrame df, use
df["col_a"]
To select "col_a" and "col_b" of df, use
df[["col_a", "col_b"]]

There are many ways to subset a DataFrame, perhaps the most common is to use relational operators to return True or False for each row, then pass that inside square brackets.
dogs[dogs["height_cm"] > 60]
dogs[dogs["color"] == "tan"]
You can filter for multiple conditions at once by using the "logical and" operator, &.
dogs[(dogs["height_cm"] > 60) & (dogs["col_b"] == "tan")]

# Filter for rows where family_members is less than 1000 
# and region is Pacific
fam_lt_1k_pac = homelessness[(homelessness["family_members"] < 1000)& (homelessness["region"] == "Pacific")]
# See the result
print(fam_lt_1k_pac)

# The Mojave Desert states
canu = ["California", "Arizona", "Nevada", "Utah"]
# Filter for rows in the Mojave Desert states
mojave_homelessness = homelessness[homelessness["state"].isin(canu)]
# See the result
print(mojave_homelessness)


Chap 1 Summary
# Create indiv_per_10k col as homeless individuals per 10k state pop
homelessness["indiv_per_10k"] = 10000 * homelessness["individuals"]/ homelessness["state_pop"]
# Subset rows for indiv_per_10k greater than 20
high_homelessness = homelessness[homelessness["indiv_per_10k"]>20]
# Sort high_homelessness by descending indiv_per_10k
high_homelessness_srt = high_homelessness.sort_values("indiv_per_10k",ascending = False)
# From high_homelessness_srt, select the state and indiv_per_10k cols
result = high_homelessness_srt[["state","indiv_per_10k"]]
# See the result
print(result)




Chap 2  Statistics
dogs["height_cm"].mean()

import numpy as np
def iqr(column):
return column.quantile(0.75) - column.quantile(0.25)
print(sales[["temperature_c", "fuel_price_usd_per_l", "unemployment"]].agg([iqr,np.median]))


sales_1_1 = sales_1_1.sort_values("date")
sales_1_1["cum_weekly_sales"] = sales_1_1["weekly_sales"].cumsum()
sales_1_1["cum_max_sales"] = sales_1_1["weekly_sales"].cummax()
print(sales_1_1[["date", "weekly_sales", "cum_weekly_sales", "cum_max_sales"]])

store_types = sales.drop_duplicates(subset=["store","type"])

# Subset the rows that are holiday weeks (Boolean format) and drop duplicate dates
holiday_dates = sales[sales["is_holiday"]].drop_duplicates(subset = "date")
OR   holiday_dates = sales[sales["is_holiday"]==True].drop_duplicates(subset = "date")
print(holiday_dates["date"])


Categorical counts
store_counts = store_types["type"].value_counts()
store_props = store_types["type"].value_counts(normalize=True)
dept_counts_sorted = store_depts["department"].value_counts(sort=True)
dept_props_sorted = store_depts["department"].value_counts(sort=True, normalize=True)


# Calc total weekly sales
sales_all = sales["weekly_sales"].sum()
sales_A = sales[sales["type"] == "A"]["weekly_sales"].sum()
# Get proportion for each type
sales_propn_by_type = [sales_A, sales_B, sales_C] / sales_all

#Group by
sales_by_type_is_holiday = sales.groupby(["type","is_holiday"])["weekly_sales"].sum()
print(sales_by_type_is_holiday)

import numpy as np
unemp_fuel_stats = sales.groupby("type")["unemployment","fuel_price_usd_per_l"].agg([np.min, np.max, np.mean,np.median])

# Print unemp_fuel_stats
print(unemp_fuel_stats)



Pivot table
# Pivot for mean weekly_sales by store type and holiday (2 variables)
mean_sales_by_type_holiday = sales.pivot_table(values="weekly_sales",index="type", columns ="is_holiday")

# Print the mean weekly_sales by department and type; fill missing values with 0s; sum all rows and cols
print(sales.pivot_table(values="weekly_sales", index="department", columns="type", fill_value=0, margins= True))



